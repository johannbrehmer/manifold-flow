{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture model on a polynomial surface: result plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import corner\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_w_err(x, yvals, ls=\"-\", m=\" \", ms=6., c=\"black\", label=None, alpha=0.1, subtract_min=False, **kwargs):\n",
    "    y_mean, y_err = np.nanmean(yvals, axis=1), np.nanstd(yvals, axis=1)\n",
    "    if subtract_min:\n",
    "        y_mean -= np.min(y_mean)\n",
    "        \n",
    "    plt.fill_between(x, y_mean - y_err, y_mean + y_err, color=c, alpha=alpha)\n",
    "    plt.plot(x, y_mean, label=label, ls=ls, marker=m, ms=ms, c=c, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histo_w_err(\n",
    "    xvals, xmin, xmax, nbins,\n",
    "    ls=\"-\", m=\" \", ms=6., c=\"black\",\n",
    "    label=None, alpha=0.1,\n",
    "    subtract_min=False, plot_individual=False,\n",
    "    **kwargs\n",
    "):\n",
    "    # Calculate histograms\n",
    "    histos = []\n",
    "    for x in xvals:\n",
    "        histo, bin_edges = np.histogram(x, bins=nbins, range=(xmin, xmax), density=True)\n",
    "        histos.append(histo)\n",
    "    histos = np.array(histos)\n",
    "\n",
    "    # Mean and error band\n",
    "    y_mean, y_err = np.nanmean(histos, axis=0), np.nanstd(histos, axis=0)\n",
    "    \n",
    "    x_ = np.repeat(bin_edges, 2)[1:-1]\n",
    "    y_ = np.repeat(y_mean, 2)\n",
    "    y_err_ = np.repeat(y_err, 2)\n",
    "    yis_ = [np.repeat(y, 2) for y in histos]\n",
    "    \n",
    "    # Plot\n",
    "    plt.fill_between(x_, y_ - y_err_, y_ + y_err_, color=c, alpha=alpha)\n",
    "    plt.plot(x_, y_, label=label, ls=ls, marker=m, ms=ms, c=c, lw=1.5, **kwargs)\n",
    "    \n",
    "    if plot_individual:\n",
    "        for yi_ in yis_:\n",
    "            plt.plot(x_, yi_, ls=ls, lw=0.5, c=c)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 3\n",
    "remove_all_results_with_nans = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_filenames = []\n",
    "algo_additionals = []\n",
    "algo_labels = []\n",
    "algo_colors = []\n",
    "algo_markers = []\n",
    "algo_linestyles = []\n",
    "\n",
    "def add_algo(filename, add, label, c, m, ls):\n",
    "    algo_filenames.append(filename)\n",
    "    algo_additionals.append(add)\n",
    "    algo_labels.append(label)\n",
    "    algo_colors.append(c)\n",
    "    algo_markers.append(m)\n",
    "    algo_linestyles.append(ls)\n",
    "    \n",
    "add_algo(\"flow\", \"_march\", \"AF\", \"C0\", \"s\", \"-\")\n",
    "add_algo(\"pie\", \"_march\", \"PIE\", \"C4\", \"s\", \"--\") \n",
    "add_algo(\"mf\", \"_march\", \"MFMF-S\", \"C3\", \"s\", \"--\")\n",
    "add_algo(\"mf\", \"_alternate_march\", \"MFMF-A\", \"C3\", \"s\", \"-\")\n",
    "add_algo(\"gamf\", \"_march\", \"MFMF-OT\", \"C1\", \"s\", \"--\") \n",
    "add_algo(\"gamf\", \"_alternate_march\", \"MFMF-OTA\", \"C1\", \"s\", \"-\") \n",
    "add_algo(\"emf\", \"_march\", \"MFMF'-S\", \"C2\", \"s\", \"--\")\n",
    "add_algo(\"emf\", \"_alternate_march\", \"MFMF'-A\", \"C2\", \"s\", \"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(name, shape, numpyfy=True, result_dir=\"../data/results\"):\n",
    "    all_results = []\n",
    "    \n",
    "    for algo_filename, algo_add in zip(algo_filenames, algo_additionals):\n",
    "        algo_results = []\n",
    "            \n",
    "        for run in range(n_runs):\n",
    "            run_str = \"\" if run == 0 else \"_run{}\".format(run)\n",
    "            try:\n",
    "                this_result = np.load(\n",
    "                    \"{}/{}_2_power{}{}_{}.npy\".format(\n",
    "                        result_dir, algo_filename, algo_add, run_str, name\n",
    "                    )\n",
    "                )\n",
    "                if (not numpyfy) or (shape is None) or np.product(this_result.shape) == np.product(shape):\n",
    "                    algo_results.append(this_result.reshape(shape))\n",
    "                else:\n",
    "                    print(this_result.shape, shape)\n",
    "                    algo_results.append(np.nan*np.ones(shape))\n",
    "                    \n",
    "            except FileNotFoundError as e:\n",
    "                if shape is None:\n",
    "                    algo_results.append(None)\n",
    "                else:\n",
    "                    algo_results.append(np.nan*np.ones(shape))\n",
    "            \n",
    "        all_results.append(algo_results)\n",
    "    \n",
    "    if numpyfy:\n",
    "        all_results = np.array(all_results, dtype=np.float)\n",
    "        \n",
    "    return all_results\n",
    "\n",
    "\n",
    "model_gen_x = load(\"samples\", None, numpyfy=False)\n",
    "model_gen_logp = load(\"samples_likelihood\", (10000,))\n",
    "model_gen_distance = load(\"samples_manifold_distance\", (10000,))\n",
    "model_test_logp = load(\"model_log_likelihood_test\", (101, 1000,))\n",
    "model_test_reco_error = load(\"model_reco_error_test\", (1000,))\n",
    "model_ood_logp = load(\"model_log_likelihood_ood\", (101, 1000,))\n",
    "model_ood_reco_error = load(\"model_reco_error_ood\", (1000,))\n",
    "model_posterior_samples = load(\"posterior_samples\", (5000, 1,))\n",
    "model_mmds = load(\"mmd\", (1,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nans(*results):\n",
    "    passes = all([np.all(np.isfinite(result)) for result in results])\n",
    "    \n",
    "    if passes:\n",
    "        return results\n",
    "    else:\n",
    "        return [np.nan * np.ones_like(result) for result in results]\n",
    "\n",
    "\n",
    "def remove_nans_from_lists(*raws):\n",
    "    # raws[quantity][algo]\n",
    "    n_quantities = len(raws)\n",
    "    n_algos = len(raws[0])\n",
    "    \n",
    "    for raw in raws:\n",
    "        assert len(raw) == n_algos\n",
    "    \n",
    "    cleans = [[[] for _ in range(n_algos)] for _ in range(n_quantities)]\n",
    "    \n",
    "    for i in range(n_algos):\n",
    "        for k in range(n_runs):\n",
    "            clean = remove_nans(*[raw[i][k] for raw in raws])\n",
    "            for j in range(n_quantities):\n",
    "                cleans[j][i].append(clean[j])\n",
    "            \n",
    "    cleans = [np.array(clean) for clean in cleans]\n",
    "    \n",
    "    # cleans[quantity][algo]\n",
    "    return cleans\n",
    "            \n",
    "    \n",
    "if remove_all_results_with_nans:\n",
    "    raw = [model_gen_logp, model_gen_distance, model_test_logp, model_ood_logp, model_ood_reco_error, model_posterior_samples, model_mmds]\n",
    "    clean = remove_nans_from_lists(*raw)\n",
    "    model_gen_logp, model_gen_distance, model_test_logp, model_ood_logp, model_ood_reco_error, model_posterior_samples, model_mmds = clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_truth(name, samples=True):\n",
    "    if samples:\n",
    "        return np.asarray([\n",
    "            np.load(\"../data/samples/power/{}{}.npy\".format(\n",
    "                name, run_str\n",
    "            ))\n",
    "            for run_str in [\"\"] + [\"_run{}\".format(i) for i in range(1, n_runs)]\n",
    "        ])\n",
    "    else:\n",
    "        return np.asarray([\n",
    "            np.load(\"../data/results/truth_power{}_{}.npy\".format(\n",
    "                run_str, name\n",
    "            ))\n",
    "            for run_str in [\"\"] + [\"_run{}\".format(i) for i in range(1, n_runs)]\n",
    "        ])\n",
    "\n",
    "test_x = load_truth(\"x_test\", True)\n",
    "test_distance = np.zeros((test_x.shape[0], 1))\n",
    "test_logp = load_truth(\"true_log_likelihood_test\", False)\n",
    "true_posterior_samples = load_truth(\"posterior_samples\", False)\n",
    "\n",
    "param_grid = np.linspace(-1, 1, 101)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_observed = 20\n",
    "min_logp = -100.\n",
    "max_distance = 10.\n",
    "\n",
    "model_gen_mean_logp = np.mean(np.clip(model_gen_logp, min_logp, None), axis=2)\n",
    "model_gen_mean_distance = np.mean(np.clip(model_gen_distance, None, max_distance), axis=2)\n",
    "model_observed_nll = -2. * np.sum(model_test_logp[:,:,:,:n_observed], axis=-1)\n",
    "\n",
    "test_mean_logp = np.mean(np.clip(test_logp, min_logp, None), axis=1)\n",
    "test_mean_distance = np.mean(np.clip(test_distance, None, max_distance), axis=1)\n",
    "true_observed_nll = -2. * np.sum(test_logp[:,:,:n_observed], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_roc_auc(x0, x1):\n",
    "    assert x0.shape == x1.shape\n",
    "    old_shape = x0.shape[:-1]\n",
    "    x0 = x0.reshape(-1, x0.shape[-1])\n",
    "    x1 = x1.reshape(-1, x1.shape[-1])\n",
    "    \n",
    "    aucs = []\n",
    "    for x0_, x1_ in zip(x0, x1):\n",
    "        if not np.all(np.isfinite(np.hstack((x0_, x1_)))):\n",
    "            aucs.append(np.nan)\n",
    "            continue\n",
    "            \n",
    "        auc = roc_auc_score(\n",
    "            np.hstack((np.zeros(x0_.shape[0], dtype=np.int), np.ones(x1_.shape[0], dtype=np.int))),\n",
    "            np.hstack((x0_, x1_)),\n",
    "        )\n",
    "        auc_flipped = roc_auc_score(\n",
    "            np.hstack((np.zeros(x0_.shape[0], dtype=np.int), np.ones(x1_.shape[0], dtype=np.int))),\n",
    "            - np.hstack((x0_, x1_)),\n",
    "        )\n",
    "        aucs.append(max(auc, auc_flipped))\n",
    "        \n",
    "    aucs = np.asarray(aucs)\n",
    "    aucs = aucs.reshape(old_shape)\n",
    "    return aucs\n",
    "\n",
    "\n",
    "model_auc_logp = calculate_roc_auc(model_test_logp[:,:,50,:], model_ood_logp[:,:,50,:])\n",
    "model_auc_err = calculate_roc_auc(model_test_reco_error, model_ood_reco_error)\n",
    "model_auc_use_err = (model_auc_err > model_auc_logp)\n",
    "model_auc = np.maximum(model_auc_err, model_auc_logp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_corner(algo=None, show=0, boundary=1.5):\n",
    "    if algo is None:\n",
    "        print(\"Simulator\")\n",
    "        x = np.load(\"../data/samples/spherical_gaussian/spherical_gaussian_2_3_0.010_x_test.npy\")\n",
    "        _ = corner.corner(x, range=[(-boundary, boundary) for _ in range(3)], bins=10)\n",
    "        \n",
    "    else:\n",
    "        print(algo_labels[algo])\n",
    "        _ = corner.corner(x_gen[algo][show], range=[(-boundary, boundary) for _ in range(3)], bins=10)\n",
    "        \n",
    "        \n",
    "def show_scatter(algo=None, show=0, boundary=1.5):\n",
    "    if algo is None:\n",
    "        print(\"Simulator\")\n",
    "        x = np.load(\"../data/samples/spherical_gaussian/spherical_gaussian_2_3_0.010_x_train.npy\")[:1000]\n",
    "    else:\n",
    "        print(algo_labels[algo])\n",
    "        x = x_gen[algo][show][:1000]\n",
    "        \n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = Axes3D(fig)\n",
    "    ax.scatter(x[:,0], x[:,1], x[:,2])\n",
    "    \n",
    "    ax.set_xlim(-boundary, boundary)\n",
    "    ax.set_ylim(-boundary, boundary)\n",
    "    ax.set_zlim(-boundary, boundary)\n",
    "    ax.set_xlabel(\"$x_0$\")\n",
    "    ax.set_ylabel(\"$x_1$\")\n",
    "    ax.set_zlabel(\"$x_2$\")\n",
    "    \n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmin, cmax = -3.,3.\n",
    "boundary = 4.0\n",
    "run = 1\n",
    "\n",
    "ncols = 3\n",
    "nrows = len(algo_labels) // ncols + 1\n",
    "\n",
    "fig = plt.figure(figsize=(ncols*4., nrows*4.1))\n",
    "\n",
    "for panel, algo in enumerate(range(-1, len(algo_labels))):\n",
    "    if algo < 0:\n",
    "        x = test_x[run, :400]\n",
    "    else:\n",
    "        if model_gen_x[algo][run] is None:\n",
    "            continue\n",
    "        else:\n",
    "            x = model_gen_x[algo][run][:400]\n",
    "\n",
    "    logp = np.clip(\n",
    "        test_logp[run, 50, :400] if algo < 0 else model_gen_logp[algo, run, :400],\n",
    "        cmin, cmax\n",
    "    )\n",
    "    d = np.clip(\n",
    "        np.zeros(x.shape[0]) if algo < 0 else model_gen_distance[algo, run, :400],\n",
    "        cmin, cmax\n",
    "    )\n",
    "    \n",
    "    ax = fig.add_subplot(nrows, ncols, panel + 1, projection=\"3d\")\n",
    "    ax.scatter(x[:,0], x[:,1], x[:,2], c=x[:,2], cmap=\"viridis\", vmin=cmin, vmax=cmax)\n",
    "\n",
    "    ax.set_xlim(-boundary, boundary)\n",
    "    ax.set_ylim(-boundary, boundary)\n",
    "    ax.set_zlim(-boundary, boundary)\n",
    "    \n",
    "    ax.set_title(\"Simulator\" if algo < 0 else algo_labels[algo])\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_zlabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/mixture_generated_samples_3d.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmin, cmax = -3., 3.\n",
    "boundary = 3.0\n",
    "run = 1\n",
    "n = 1000\n",
    "\n",
    "ncols = 3\n",
    "nrows = len(algo_labels) // ncols + 1\n",
    "\n",
    "fig = plt.figure(figsize=(ncols*4., nrows*4.1))\n",
    "\n",
    "for panel, algo in enumerate(range(-1, len(algo_labels))):\n",
    "    if algo < 0:\n",
    "        x = test_x[run, :n]\n",
    "    else:\n",
    "        if model_gen_x[algo][run] is None:\n",
    "            continue\n",
    "        else:\n",
    "            x = model_gen_x[algo][run][:n]\n",
    "\n",
    "    logp = np.clip(\n",
    "        test_logp[run, 50, :n] if algo < 0 else model_gen_logp[algo, run, :n],\n",
    "        cmin, cmax\n",
    "    )\n",
    "    \n",
    "    ax = fig.add_subplot(nrows, ncols, panel + 1)\n",
    "    plt.scatter(x[:,0], x[:,1], c=x[:,2], cmap=\"viridis\", s=5., vmin=cmin, vmax=cmax)\n",
    "\n",
    "    ax.set_xlim(-boundary, boundary)\n",
    "    ax.set_ylim(-boundary, boundary)\n",
    "    \n",
    "    ax.set_title(\"Simulator\" if algo < 0 else algo_labels[algo])\n",
    "    ax.set_xlabel(\"$x_0$\")\n",
    "    ax.set_ylabel(\"$x_1$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/mixture_generated_samples_2d.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot eval likelihood on test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmin, cmax = -6., 4.\n",
    "boundary = 4.0\n",
    "param_points = [0, 50, 100]\n",
    "run = 1\n",
    "n = 1000\n",
    "\n",
    "ncols = len(algo_labels) + 1\n",
    "nrows = len(param_points)\n",
    "\n",
    "fig = plt.figure(figsize=(ncols*4, nrows*4))\n",
    "\n",
    "for col, algo in enumerate(range(-1, len(algo_labels))):\n",
    "    for row, param in enumerate(param_points):\n",
    "        x = test_x[run, :n]\n",
    "        if algo > 0 and model_test_logp[algo, run] is None:\n",
    "            continue\n",
    "        else:\n",
    "            logp = np.clip(\n",
    "                test_logp[run, param, :n] if algo < 0 else model_test_logp[algo, run, param, :n],\n",
    "                cmin, cmax\n",
    "            )\n",
    "        \n",
    "        ax = fig.add_subplot(nrows, ncols, row * ncols + col + 1, projection=\"3d\")\n",
    "        ax.scatter(x[:,0], x[:,1], x[:,2], c=logp, vmin=cmin, vmax=cmax, cmap=\"viridis\")\n",
    "\n",
    "        ax.set_xlim(-boundary, boundary)\n",
    "        ax.set_ylim(-boundary, boundary)\n",
    "        ax.set_zlim(-boundary, boundary)\n",
    "        \n",
    "        if row == 0:\n",
    "            ax.set_title(\"Simulator\" if algo < 0 else algo_labels[algo])\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_zlabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/mixture_test_likelihood_3d.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood estimation quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 0\n",
    "param_points = [0, 50, 100]\n",
    "\n",
    "ncols = len(algo_labels)\n",
    "nrows = len(param_points)\n",
    "\n",
    "fig = plt.figure(figsize=(ncols*5, nrows*4))\n",
    "\n",
    "for col, algo_label in enumerate(algo_labels):\n",
    "    for row, param in enumerate(param_points):\n",
    "        ax = plt.subplot(nrows, ncols, row*ncols + col + 1)\n",
    "        \n",
    "        plt.plot([-8, 8.], [-8.,8.], ls=\":\", c=\"0.5\", lw=1.)\n",
    "        sc = plt.scatter(\n",
    "            test_logp[run, param, :500],\n",
    "            model_test_logp[col, run, param, :500],\n",
    "            # c=np.log(np.clip(model_test_reco_error[col, setting,:500], np.exp(-10.), np.exp(10.))),\n",
    "            c=model_test_reco_error[col, run, :500],\n",
    "            s=10.,\n",
    "            label=algo_label,\n",
    "            cmap=\"viridis_r\",\n",
    "            vmin=0., vmax=1.\n",
    "        )\n",
    "        cbar = plt.colorbar(sc)\n",
    "        \n",
    "        plt.xlabel(r\"True log likelihood\")\n",
    "        plt.ylabel(r\"{} log likelihood\".format(algo_label))\n",
    "        cbar.set_label('Reco error')\n",
    "        \n",
    "        if row == 0:\n",
    "            ax.set_title(algo_label)\n",
    "        \n",
    "        plt.xlim(-12.,12.)\n",
    "        plt.ylim(-12.,12.)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/mixture_test_likelihood_scatter.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOD detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 2\n",
    "\n",
    "ncols = 3\n",
    "nrows = (len(algo_labels) - 1) // ncols + 1\n",
    "\n",
    "fig = plt.figure(figsize=(ncols*4, nrows*4))\n",
    "\n",
    "for algo, algo_label in enumerate(algo_labels):\n",
    "    ax = plt.subplot(nrows, ncols, algo + 1)\n",
    "\n",
    "    logp = model_test_logp[algo, run, 50]\n",
    "    logp_ood = model_ood_logp[algo, run, 50]\n",
    "    err = model_test_reco_error[algo, run]\n",
    "    err_ood = model_ood_reco_error[algo, run]\n",
    "    \n",
    "    if np.any(np.isnan(logp)):\n",
    "        continue\n",
    "\n",
    "    use_err = model_auc_use_err[algo, run]\n",
    "    x = err if use_err else logp\n",
    "    x_ood = err_ood if use_err else logp_ood\n",
    "    \n",
    "    xmin, xmax = np.percentile(np.concatenate((x, x_ood)), (2., 98.))\n",
    "    xmin -= (xmax - xmin)*0.05\n",
    "    xmax += (xmax - xmin)*0.05\n",
    "\n",
    "    plt.hist(x, color=\"C0\", bins=100, range=(xmin, xmax), histtype=\"step\", lw=1.5)\n",
    "    plt.hist(x_ood, color=\"C1\", bins=100, range=(xmin, xmax), histtype=\"step\", lw=1.5)\n",
    "\n",
    "    plt.xlabel((\"{} reco error\" if use_err else \"{} log likelihood\").format(algo_label))\n",
    "    plt.ylabel(\"Histogram\")\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.ylim(0., None)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/mixture_ood_separation.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = 0.,0.1\n",
    "bins = 50\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "ax = plt.gca()\n",
    "    \n",
    "histo_w_err(\n",
    "    test_distance[run,:],\n",
    "    xmin, xmax, bins,\n",
    "    label=\"Simulator\",\n",
    "    c=\"black\",\n",
    ")\n",
    "\n",
    "for algo, (algo_label, c, m, ls) in enumerate(zip(algo_labels, algo_colors, algo_markers, algo_linestyles)):\n",
    "    histo_w_err(\n",
    "        model_gen_distance[algo, run, :],\n",
    "        xmin, xmax, bins,\n",
    "        label=algo_label,\n",
    "        c=c,\n",
    "        ls=ls,\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(r\"Distance to manifold\")\n",
    "plt.ylabel(r\"Histogram\")\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(1.e-1, 1.e3)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/mixture_generated_samples_distance_distribution.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "plot_w_err(param_grid, true_observed_nll.T - np.min(true_observed_nll, axis=1), ls=\"--\", c=\"black\", label=\"Simulator\", subtract_min=True)\n",
    "for nll, label, c, ls, mmd in zip(model_observed_nll, algo_labels, algo_colors, algo_linestyles, model_mmds):\n",
    "    logp = nll.T - np.min(nll, axis=1)\n",
    "    plot_w_err(param_grid, logp, ls=ls, c=c, label=label, subtract_min=True)\n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(r\"$\\theta$\")\n",
    "plt.ylabel(r\"$-2 \\log \\Delta {p(x|\\theta)$\")\n",
    "\n",
    "plt.ylim(0., 25.)\n",
    "plt.xlim(-1.,1.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/mixture_test_observed_likelihood_maps.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "histo_w_err(\n",
    "    true_posterior_samples,-1., 1., 50,\n",
    "    ls=\"-\", c=\"black\", alpha=0.15,\n",
    "    label=\"Simulator\",\n",
    "    subtract_min=True, plot_individual=False\n",
    ")\n",
    "for posterior, label, c, ls in zip(model_posterior_samples, algo_labels, algo_colors, algo_linestyles):\n",
    "    histo_w_err(\n",
    "        posterior, -1., 1., 50,\n",
    "        ls=ls, c=c, alpha=0.15, \n",
    "        label=label,\n",
    "        subtract_min=True, plot_individual=False\n",
    "    )\n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(r\"$\\theta$\")\n",
    "plt.ylabel(r\"$p(\\theta|x)$\")\n",
    "\n",
    "plt.ylim(0., 2.)\n",
    "plt.xlim(-1.,1.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/mixture_posterior.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
